{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f958749-3085-43b4-8a23-13cf5af54e83",
   "metadata": {},
   "source": [
    "# CHAPTER 5 - Lab: Cross-Validation and the Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ca454-125d-4def-9e91-d2715d02fe97",
   "metadata": {},
   "source": [
    "In this lab, we explore the resampling techniques covered in this chapter. Some of the commands in this lab may take a while to run on your\n",
    "computer.\n",
    "We again begin by placing most of our imports at this top level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac837e4-9324-4729-adb5-21c2e0fc534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "summarize ,\n",
    "poly)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8314be59-2963-4976-a710-7a14a0d5ebfb",
   "metadata": {},
   "source": [
    "There are several new imports needed for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c552f7f-0857-480d-8f5d-5cf24d26754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "(cross_validate,\n",
    "KFold,\n",
    "ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49657756-af4f-4f78-a1ac-518e0f13e1ec",
   "metadata": {},
   "source": [
    "<h4>The Validation Set Approach</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a30e88-4f10-4ca1-b046-6de4f5b36583",
   "metadata": {},
   "source": [
    "We use the function train_test_split() to split the data into training  and validation sets. As there are 392 observations, we split into two equal\n",
    "sets of size 196 using the argument test_size=196. It is generally a good\n",
    "idea to set a random seed when performing operations like this that contain\n",
    "an element of randomness, so that the results obtained can be reproduced\n",
    "precisely at a later time. We set the random seed of the splitter with the\n",
    "argument random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be8d0ed7-5a6b-41fe-8736-78ff7834b92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  mpg  cylinders  displacement  horsepower  \\\n",
      "name                                                                         \n",
      "mercury monarch ghia             20.2          8         302.0         139   \n",
      "amc gremlin                      21.0          6         199.0          90   \n",
      "buick regal sport coupe (turbo)  17.7          6         231.0         165   \n",
      "amc hornet sportabout (sw)       18.0          6         258.0         110   \n",
      "plymouth volare custom           19.0          6         225.0         100   \n",
      "\n",
      "                                 weight  acceleration  year  origin  \n",
      "name                                                                 \n",
      "mercury monarch ghia               3570          12.8    78       1  \n",
      "amc gremlin                        2648          15.0    70       1  \n",
      "buick regal sport coupe (turbo)    3445          13.4    78       1  \n",
      "amc hornet sportabout (sw)         2962          13.5    71       1  \n",
      "plymouth volare custom             3630          17.7    77       1  \n",
      "                             mpg  cylinders  displacement  horsepower  weight  \\\n",
      "name                                                                            \n",
      "dodge colt                  28.0          4          90.0          75    2125   \n",
      "ford fairmont 4             22.3          4         140.0          88    2890   \n",
      "oldsmobile delta 88 royale  12.0          8         350.0         160    4456   \n",
      "plymouth horizon miser      38.0          4         105.0          63    2125   \n",
      "subaru dl                   33.8          4          97.0          67    2145   \n",
      "\n",
      "                            acceleration  year  origin  \n",
      "name                                                    \n",
      "dodge colt                          14.5    74       1  \n",
      "ford fairmont 4                     17.3    79       1  \n",
      "oldsmobile delta 88 royale          13.5    72       1  \n",
      "plymouth horizon miser              14.7    82       1  \n",
      "subaru dl                           18.0    80       3  \n"
     ]
    }
   ],
   "source": [
    "Auto = load_data('Auto')\n",
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "test_size=196,\n",
    "random_state=0)\n",
    "\n",
    "print(Auto_train.head()),\n",
    "\n",
    "print(Auto_valid.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f91c15-e5a7-4bda-adec-cd6105ea8ab1",
   "metadata": {},
   "source": [
    "Now we can fit a linear regression using only the observations corresponding to the training set Auto_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1963917-55a8-4840-adec-831f8fca9831",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368ba027-bc8e-4a85-9fec-774cfd9832cf",
   "metadata": {},
   "source": [
    "We now use the predict() method of results evaluated on the model matrix for this model created using the validation data set. We also calculate\n",
    "the validation MSE of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a51e405-4a39-4b75-9ce6-64b4dd06b05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(23.61661706966988)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7dbad0-c0f3-4ee9-8fbe-35f061bd5b52",
   "metadata": {},
   "source": [
    "Hence our estimate for the validation MSE of the linear regression fit is\n",
    "23.62.\n",
    "We can also estimate the validation error for higher-degree polynomial\n",
    "regressions. We first provide a function evalMSE() that takes a model string\n",
    "as well as a training and test set and returns the MSE on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2010706a-544d-4fe6-9c69-ee5d514ac454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMSE(terms,\n",
    "            response,\n",
    "            train,\n",
    "            test):\n",
    "    mm = MS(terms)\n",
    "    X_train = mm.fit_transform(train)\n",
    "    y_train = train[response]\n",
    "    X_test = mm.transform(test)\n",
    "    y_test = test[response]\n",
    "    results = sm.OLS(y_train, X_train).fit()\n",
    "    test_pred = results.predict(X_test)\n",
    "    return np.mean((y_test - test_pred)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe7a51-3762-405e-ad64-b7ce15b5a2e4",
   "metadata": {},
   "source": [
    "Let’s use this function to estimate the validation MSE using linear,\n",
    "quadratic and cubic fits. We use the enumerate() function here, which gives enumerate() both the values and indices of objects as one iterates over a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a81d7a20-5412-47ab-963f-e9bc83a56149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707, 18.76303135, 18.79694163])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an array to store MSE for degrees 1, 2, 3\n",
    "MSE = np.zeros(3)\n",
    "\n",
    "# Loop through polynomial degrees 1, 2, 3\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                        'mpg',\n",
    "                        Auto_train,\n",
    "                        Auto_valid)\n",
    "\n",
    "# Display the MSE array\n",
    "MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1473483f-c54f-464f-ba8e-0bc5d0e3e592",
   "metadata": {},
   "source": [
    "These error rates are 23.62, 18.76, and 18.80, respectively. If we choose a\n",
    "different training/validation split instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee7d045-6a7e-440c-b51a-f759ba49e33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset into training and validation sets\n",
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                          test_size=196,\n",
    "                                          random_state=3)\n",
    "\n",
    "# Initialize array to store MSE for polynomial degrees 1, 2, 3\n",
    "MSE = np.zeros(3)\n",
    "\n",
    "# Loop over polynomial degrees\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                        'mpg',\n",
    "                        Auto_train,\n",
    "                        Auto_valid)\n",
    "\n",
    "# Display the MSE array\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5727dfe6-4c46-4eb7-9adb-d87e95ab31c2",
   "metadata": {},
   "source": [
    "The class sklearn_sm() has as its first argument a model from statsmodels.\n",
    "It can take two additional optional arguments: model_str which can be used\n",
    "to specify a formula, and model_args which should be a dictionary of additional arguments used when fitting the model. For example, to fit a logistic\n",
    "regression model we have to specify a family argument. This is passed as\n",
    "model_args={'family':sm.families.Binomial()}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccab1798-6836-4c73-837d-3b1277936a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(24.231513517929212)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model = sklearn_sm(sm.OLS,\n",
    "MS(['horsepower']))\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
    "cv_results = cross_validate(hp_model,\n",
    "X,\n",
    "Y,\n",
    "cv=Auto.shape[0])\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276d93d-1783-43c2-97b5-2fd8bdab640f",
   "metadata": {},
   "source": [
    "The arguments to cross_validate() are as follows: an object with the appropriate fit(), predict(), and score() methods, an array of features X and\n",
    "a response Y. We also included an additional argument cv to cross_validate();\n",
    "specifying an integer K results in K-fold cross-validation. We have provided\n",
    "a value corresponding to the total number of observations, which results\n",
    "in leave-one-out cross-validation (LOOCV). The cross_validate() func- cross_\n",
    "tion produces a dictionary with several components; we simply want the validate()\n",
    "cross-validated test score here (MSE), which is estimated to be 24.23.\n",
    "We can repeat this procedure for increasingly complex polynomial fits.\n",
    "To automate the process, we again use a for loop which iteratively fits\n",
    "polynomial regressions of degree 1 to 5, computes the associated crossvalidation error, and stores it in the ith element of the vector cv_error.\n",
    "The variable d in the for loop corresponds to the degree of the polynomial.\n",
    "We begin by initializing the vector. This command may take a couple of\n",
    "seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c7fd2f0-4f69-49df-981d-2c11a81a1daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.23151352, 19.24821312, 19.33498406, 19.42443031, 19.03320428])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "Y = np.array(Auto['mpg'])\n",
    "M = sklearn_sm(sm.OLS)\n",
    "\n",
    "for i, d in enumerate(range(1, 6)):\n",
    "    # Design matrix for polynomial regression\n",
    "    X = np.column_stack([H**p for p in range(d+1)])\n",
    "    \n",
    "    # LOOCV with MSE\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=Auto.shape[0],                # LOOCV\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          return_train_score=False)\n",
    "    \n",
    "    # Store MSE (convert negative to positive)\n",
    "    cv_error[i] = -np.mean(M_CV['test_score'])\n",
    "\n",
    "cv_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950ddb96-b7dc-4288-88d9-51082567e00f",
   "metadata": {},
   "source": [
    "Above we introduced the outer() method of the np.power() function. .outer()\n",
    "np.power() The outer() method is applied to an operation that has two arguments,\n",
    "such as add(), min(), or power(). It has two arrays as arguments, and then\n",
    "forms a larger array where the operation is applied to each pair of elements\n",
    "of the two arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccc8b32f-8e0b-4bac-9881-9e3cb1071af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7],\n",
       "       [ 7,  9],\n",
       "       [11, 13]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([3, 5, 9])\n",
    "B = np.array([2, 4])\n",
    "np.add.outer(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4cf75-35fd-4903-a21b-1101b7a80a93",
   "metadata": {},
   "source": [
    "In the CV example above, we used K = n, but of course we can also use\n",
    "K<n. The code is very similar to the above (and is significantly faster).\n",
    "Here we use KFold() to partition the data into K = 10 random groups. We KFold()\n",
    "use random_state to set a random seed and initialize a vector cv_error in\n",
    "which we will store the CV errors corresponding to the polynomial fits of\n",
    "degrees one to five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb3e7600-3c60-47e6-bf5c-eb0cf92850db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.20766449, 19.18533142, 19.27626666, 19.47848404, 19.13722016])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "\n",
    "# Use the same K-Fold splits for all degrees\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "for i, d in enumerate(range(1, 6)):\n",
    "    # Create polynomial design matrix for degree d\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=cv)\n",
    "    \n",
    "    # Store mean test score\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "\n",
    "# Display cross-validation errors\n",
    "cv_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01accd70-8e55-4a17-a887-039ed0ecf104",
   "metadata": {},
   "source": [
    "The cross_validate() function is flexible and can take different splitting\n",
    "mechanisms as an argument. For instance, one can use the funtion to implement the validation set approach just as easily as K-fold\n",
    "cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e89f7c52-d7c4-411d-95c3-06edcf83f7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=1,\n",
    "test_size=196,\n",
    "random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "Auto.drop(['mpg'], axis=1),\n",
    "Auto['mpg'],\n",
    "cv=validation);\n",
    "results['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e3ca79-f078-4326-a4e7-7f095ff9c5d7",
   "metadata": {},
   "source": [
    "One can estimate the variability in the test error by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "171d88c9-8753-4a47-881f-5cba5bcf8b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(23.802232661034164), np.float64(1.4218450941091847))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=10,\n",
    "test_size=196,\n",
    "random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "Auto.drop(['mpg'], axis=1),\n",
    "Auto['mpg'],\n",
    "cv=validation)\n",
    "results['test_score'].mean(), results['test_score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e0712-d8b2-4fc9-8432-62573c2c643c",
   "metadata": {},
   "source": [
    "<h4>Estimating the Accuracy of a Statistic of Interest</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bdef95-797c-49e4-aeb9-8fc45dc63027",
   "metadata": {},
   "source": [
    "We will create a function alpha_func(), which takes as input a dataframe D\n",
    "assumed to have columns X and Y, as well as a vector idx indicating which\n",
    "observations should be used to estimate α. The function then outputs the\n",
    "estimate for α based on the selected observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52d8660e-84ba-4d07-87da-d14ce8e82428",
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfolio = load_data('Portfolio')\n",
    "\n",
    "def alpha_func(D, idx):\n",
    "    cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
    "    return ( (cov_[1,1] - cov_[0,1]) / (cov_[0,0] + cov_[1,1] - 2*cov_[0,1]) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9aa7f8-90cd-4b80-a829-02ab120cf792",
   "metadata": {},
   "source": [
    "This function returns an estimate for α based on applying the minimum\n",
    "variance formula (5.7) to the observations indexed by the argument idx. For\n",
    "instance, the following command estimates α using all 100 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f21e7039-3bf7-4e9c-80c4-f8976890b384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.57583207459283)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_func(Portfolio, range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fda8cb-d96b-401e-8321-7adbb0baffdf",
   "metadata": {},
   "source": [
    "Next we randomly select 100 observations from range(100), with replacement. This is equivalent to constructing a new bootstrap data set and\n",
    "recomputing αˆ based on the new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ff028fb-7243-4318-b5a3-d284ba2e6341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6074452469619004)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "alpha_func(Portfolio,\n",
    "rng.choice(100,\n",
    "100,\n",
    "replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7795ccf-fea1-4fcd-a79b-bfa73ca27c37",
   "metadata": {},
   "source": [
    "This process can be generalized to create a simple function boot_SE() for\n",
    "computing the bootstrap standard error for arbitrary functions that take\n",
    "only a data frame as an argumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1287ce81-3239-4ebc-affc-f2b6c7d98900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_SE(func,\n",
    "            D,\n",
    "            n=None,\n",
    "            B=1000,\n",
    "            seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index,\n",
    "                         n,\n",
    "                         replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b718d6-925d-42c4-bc1a-8b475bbf8365",
   "metadata": {},
   "source": [
    "Notice the use of _ as a loop variable in for _ in range(B). This is often\n",
    "used if the value of the counter is unimportant and simply makes sure the\n",
    "loop is executed B times.\n",
    "Let’s use our function to evaluate the accuracy of our estimate of α using\n",
    "B = 1,000 bootstrap replications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc2dca5f-b426-4650-b0bd-5c4721928f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.09118176521277699)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_SE = boot_SE(alpha_func,\n",
    "                   Portfolio,\n",
    "                   B=1000,\n",
    "                   seed=0)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a4a062-024f-4af5-9931-b79058bc401a",
   "metadata": {},
   "source": [
    "<h4>Estimating the Accuracy of a Linear Regression Model</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e61b766-1628-43ec-a6a6-be473db364c6",
   "metadata": {},
   "source": [
    "We start by writing a generic function boot_OLS() for bootstrapping a\n",
    "regression model that takes a formula to define the corresponding regression. We use the clone() function to make a copy of the formula that can clone() be refit to the new dataframe. This means that any derived features such\n",
    "as those defined by poly() (which we will see shortly), will be re-fit on the\n",
    "resampled data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a841df1-cb2a-41c5-981d-71f02223adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_OLS(model_matrix, response, D, idx):\n",
    "    D_ = D.iloc[idx]  \n",
    "    Y_ = D_[response]\n",
    "    X_ = clone(model_matrix).fit_transform(D_)\n",
    "    return sm.OLS(Y_, X_).fit().params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f32684a-1a90-4f00-b24e-60e7b21285f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6297f1a9-31f2-4fd5-8581-155d519d9c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.88064456, -0.1567849 ],\n",
       "       [38.73298691, -0.14699495],\n",
       "       [38.31734657, -0.14442683],\n",
       "       [39.91446826, -0.15782234],\n",
       "       [39.43349349, -0.15072702],\n",
       "       [40.36629857, -0.15912217],\n",
       "       [39.62334517, -0.15449117],\n",
       "       [39.0580588 , -0.14952908],\n",
       "       [38.66688437, -0.14521037],\n",
       "       [39.64280792, -0.15555698]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "\n",
    "np.array([\n",
    "    hp_func(Auto, rng.choice(Auto.shape[0], Auto.shape[0], replace=True))\n",
    "    for _ in range(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff23d1a-478c-493c-b631-0fb11ab15cbb",
   "metadata": {},
   "source": [
    "Next, we use the boot_SE() function to compute the standard errors of\n",
    "1,000 bootstrap estimates for the intercept and slope terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05f7fe6e-63bd-4c00-a954-9c1026fe36df",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'chevrolet citation'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_15076\\3388638728.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m hp_se = boot_SE(hp_func ,\n\u001b[32m      2\u001b[39m                 Auto ,\n\u001b[32m      3\u001b[39m                 B=\u001b[32m1000\u001b[39m,\n\u001b[32m      4\u001b[39m                 seed=\u001b[32m10\u001b[39m)\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_15076\\1710545028.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(func, D, n, B, seed)\u001b[39m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;28;01min\u001b[39;00m range(B):\n\u001b[32m     10\u001b[39m         idx = rng.choice(D.index,\n\u001b[32m     11\u001b[39m                          n,\n\u001b[32m     12\u001b[39m                          replace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m         value = func(D, idx)\n\u001b[32m     14\u001b[39m         first_ += value\n\u001b[32m     15\u001b[39m         second_ += value**\u001b[32m2\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.sqrt(second_ / B - (first_ / B)**\u001b[32m2\u001b[39m)\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_15076\\2536024432.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(model_matrix, response, D, idx)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m boot_OLS(model_matrix, response, D, idx):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     D_ = D.iloc[idx]\n\u001b[32m      3\u001b[39m     Y_ = D_[response]\n\u001b[32m      4\u001b[39m     X_ = clone(model_matrix).fit_transform(D_)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m sm.OLS(Y_, X_).fit().params\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexing.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1187\u001b[39m             axis = self.axis \u001b[38;5;28;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m   1188\u001b[39m \n\u001b[32m   1189\u001b[39m             maybe_callable = com.apply_if_callable(key, self.obj)\n\u001b[32m   1190\u001b[39m             maybe_callable = self._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._getitem_axis(maybe_callable, axis=axis)\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexing.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1739\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._getbool_axis(key, axis=axis)\n\u001b[32m   1740\u001b[39m \n\u001b[32m   1741\u001b[39m         \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[32m   1742\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._get_list_axis(key, axis=axis)\n\u001b[32m   1744\u001b[39m \n\u001b[32m   1745\u001b[39m         \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[32m   1746\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexing.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1711\u001b[39m         `axis` can only be zero.\n\u001b[32m   1712\u001b[39m         \"\"\"\n\u001b[32m   1713\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1714\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.obj._take_with_is_copy(key, axis=axis)\n\u001b[32m-> \u001b[39m\u001b[32m1715\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m IndexError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1716\u001b[39m             \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[32m   1717\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m IndexError(\u001b[33m\"positional indexers are out-of-bounds\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m err\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, indices, axis)\u001b[39m\n\u001b[32m   4168\u001b[39m         For Series this does the same \u001b[38;5;28;01mas\u001b[39;00m the public take (it never sets `_is_copy`).\n\u001b[32m   4169\u001b[39m \n\u001b[32m   4170\u001b[39m         See the docstring of `take` \u001b[38;5;28;01mfor\u001b[39;00m full explanation of the parameters.\n\u001b[32m   4171\u001b[39m         \"\"\"\n\u001b[32m-> \u001b[39m\u001b[32m4172\u001b[39m         result = self.take(indices=indices, axis=axis)\n\u001b[32m   4173\u001b[39m         \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[32m   4174\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self.ndim == \u001b[32m2\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m result._get_axis(axis).equals(self._get_axis(axis)):\n\u001b[32m   4175\u001b[39m             result._set_is_copy(self)\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, indices, axis, **kwargs)\u001b[39m\n\u001b[32m   4121\u001b[39m \n\u001b[32m   4122\u001b[39m         nv.validate_take((), kwargs)\n\u001b[32m   4123\u001b[39m \n\u001b[32m   4124\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(indices, slice):\n\u001b[32m-> \u001b[39m\u001b[32m4125\u001b[39m             indices = np.asarray(indices, dtype=np.intp)\n\u001b[32m   4126\u001b[39m             if (\n\u001b[32m   4127\u001b[39m                 axis == \u001b[32m0\u001b[39m\n\u001b[32m   4128\u001b[39m                 \u001b[38;5;28;01mand\u001b[39;00m indices.ndim == \u001b[32m1\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: 'chevrolet citation'"
     ]
    }
   ],
   "source": [
    "hp_se = boot_SE(hp_func ,\n",
    "                Auto ,\n",
    "                B=1000,\n",
    "                seed=10)\n",
    "hp_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c46a29-63da-48b8-bb53-081dc762f746",
   "metadata": {},
   "source": [
    "This indicates that the bootstrap estimate for SE(βˆ0) is 0.85, and that\n",
    "the bootstrap estimate for SE(βˆ1) is 0.0074. As discussed in Section 3.1.2,\n",
    "standard formulas can be used to compute the standard errors for the\n",
    "regression coefficients in a linear model. These can be obtained using the\n",
    "summarize() function from ISLP.sm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77329503-1820-4584-97e8-7df4b600e9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.717\n",
       "horsepower    0.006\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model.fit(Auto, Auto['mpg'])\n",
    "model_se = summarize(hp_model.results_)['std err']\n",
    "model_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad3e7ab-e8b2-4bb5-86ec-aeed317d2f11",
   "metadata": {},
   "source": [
    "Below we compute the bootstrap standard error estimates and the standard linear regression estimates that result from fitting the quadratic model\n",
    "to the data. Since this model provides a good fit to the data (Figure 3.8),\n",
    "there is now a better correspondence between the bootstrap estimates and\n",
    "the standard estimates of SE(βˆ0), SE(βˆ1) and SE(βˆ2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e13f4884-0b33-4dd9-bba3-cbd59d723a25",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'honda accord'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_15076\\2572290261.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m quad_model = MS([poly(\u001b[33m'horsepower'\u001b[39m, \u001b[32m2\u001b[39m, raw=\u001b[38;5;28;01mTrue\u001b[39;00m)])\n\u001b[32m      2\u001b[39m quad_func = partial(boot_OLS,\n\u001b[32m      3\u001b[39m quad_model,\n\u001b[32m      4\u001b[39m \u001b[33m'mpg'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m boot_SE(quad_func, Auto, B=\u001b[32m1000\u001b[39m)\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_15076\\1710545028.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(func, D, n, B, seed)\u001b[39m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;28;01min\u001b[39;00m range(B):\n\u001b[32m     10\u001b[39m         idx = rng.choice(D.index,\n\u001b[32m     11\u001b[39m                          n,\n\u001b[32m     12\u001b[39m                          replace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m         value = func(D, idx)\n\u001b[32m     14\u001b[39m         first_ += value\n\u001b[32m     15\u001b[39m         second_ += value**\u001b[32m2\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.sqrt(second_ / B - (first_ / B)**\u001b[32m2\u001b[39m)\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_15076\\1386921687.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(model_matrix, response, D, idx)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m boot_OLS(model_matrix, response, D, idx):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     D_ = D.iloc[idx]  \u001b[38;5;66;03m# Use iloc to index by integer positions\u001b[39;00m\n\u001b[32m      3\u001b[39m     Y_ = D_[response]\n\u001b[32m      4\u001b[39m     X_ = clone(model_matrix).fit_transform(D_)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m sm.OLS(Y_, X_).fit().params\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexing.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1187\u001b[39m             axis = self.axis \u001b[38;5;28;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m   1188\u001b[39m \n\u001b[32m   1189\u001b[39m             maybe_callable = com.apply_if_callable(key, self.obj)\n\u001b[32m   1190\u001b[39m             maybe_callable = self._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._getitem_axis(maybe_callable, axis=axis)\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexing.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1739\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._getbool_axis(key, axis=axis)\n\u001b[32m   1740\u001b[39m \n\u001b[32m   1741\u001b[39m         \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[32m   1742\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._get_list_axis(key, axis=axis)\n\u001b[32m   1744\u001b[39m \n\u001b[32m   1745\u001b[39m         \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[32m   1746\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexing.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1711\u001b[39m         `axis` can only be zero.\n\u001b[32m   1712\u001b[39m         \"\"\"\n\u001b[32m   1713\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1714\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.obj._take_with_is_copy(key, axis=axis)\n\u001b[32m-> \u001b[39m\u001b[32m1715\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m IndexError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1716\u001b[39m             \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[32m   1717\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m IndexError(\u001b[33m\"positional indexers are out-of-bounds\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m err\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, indices, axis)\u001b[39m\n\u001b[32m   4168\u001b[39m         For Series this does the same \u001b[38;5;28;01mas\u001b[39;00m the public take (it never sets `_is_copy`).\n\u001b[32m   4169\u001b[39m \n\u001b[32m   4170\u001b[39m         See the docstring of `take` \u001b[38;5;28;01mfor\u001b[39;00m full explanation of the parameters.\n\u001b[32m   4171\u001b[39m         \"\"\"\n\u001b[32m-> \u001b[39m\u001b[32m4172\u001b[39m         result = self.take(indices=indices, axis=axis)\n\u001b[32m   4173\u001b[39m         \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[32m   4174\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self.ndim == \u001b[32m2\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m result._get_axis(axis).equals(self._get_axis(axis)):\n\u001b[32m   4175\u001b[39m             result._set_is_copy(self)\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, indices, axis, **kwargs)\u001b[39m\n\u001b[32m   4121\u001b[39m \n\u001b[32m   4122\u001b[39m         nv.validate_take((), kwargs)\n\u001b[32m   4123\u001b[39m \n\u001b[32m   4124\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(indices, slice):\n\u001b[32m-> \u001b[39m\u001b[32m4125\u001b[39m             indices = np.asarray(indices, dtype=np.intp)\n\u001b[32m   4126\u001b[39m             if (\n\u001b[32m   4127\u001b[39m                 axis == \u001b[32m0\u001b[39m\n\u001b[32m   4128\u001b[39m                 \u001b[38;5;28;01mand\u001b[39;00m indices.ndim == \u001b[32m1\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: 'honda accord'"
     ]
    }
   ],
   "source": [
    "quad_model = MS([poly('horsepower', 2, raw=True)])\n",
    "quad_func = partial(boot_OLS,\n",
    "quad_model,\n",
    "'mpg')\n",
    "boot_SE(quad_func, Auto, B=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a2374-dcb8-4684-bbad-9e009130c83c",
   "metadata": {},
   "source": [
    "We compare the results to the standard errors computed using sm.OLS()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "428db924-e491-4285-abb7-99bad379e6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept                                  1.800\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.031\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sm.OLS(Auto['mpg'],\n",
    "quad_model.fit_transform(Auto))\n",
    "summarize(M.fit())['std err']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3745a3-2a85-430a-a555-f1f427f3db11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
